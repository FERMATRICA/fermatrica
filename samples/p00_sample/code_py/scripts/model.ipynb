{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pkgutil\n",
    "import re\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "main_curr_dir = os.getcwd()\n",
    "if os.path.basename(os.getcwd()) == 'scripts':\n",
    "    os.chdir(\"../../\")\n",
    "\n",
    "import fermatrica as fm\n",
    "import fermatrica_rep as fmr\n",
    "\n",
    "import code_py.adhoc.model\n",
    "import code_py.adhoc.reporting\n",
    "\n",
    "metrics_max = 0\n",
    "metrics_min = np.inf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "# script settings\n",
    "\n",
    "product_price = 1  # set current product price\n",
    "conversion_rate = 1  # change only if some kind of convertion is expected\n",
    "\n",
    "if_opt = True  # optimize / run w/o optimizing\n",
    "cur_algo = 'local'  # 'global' / 'local'\n",
    "if_visual = True  # switch on/off visuals\n",
    "if_curves = True  # separate cause of media prices\n",
    "if_save = False  # save model and for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to set model\n",
    "\n",
    "1. Create or copy project with following structure:\n",
    "    ```-[root]\n",
    "        -code_py\n",
    "            -adhoc\n",
    "                -__init__.py\n",
    "                -model.py [optional]\n",
    "            -model_data\n",
    "                -model_def.xlsx\n",
    "            -scripts\n",
    "                -model.ipynb\n",
    "                \n",
    "2. File \"model_def.xlsx\"\n",
    "    1. Setup (model type, Y var, (product) price var, target brand, series frequency, conversion): sheet \"setup\"\n",
    "    2. RHS (linear model specs): sheet \"RHS\"\n",
    "    3. Transformations: sheet \"params\"\n",
    "    4. Scoring (mostly for optimising): sheet \"scoring\"\n",
    "    5. LHS (optional, Y transformations): sheet \"LHS\"\n",
    "3. Data file\n",
    "    1. Mandatory fields:\n",
    "        1. \"superbrand\" (string): brand name\n",
    "        2. \"bs_key\" (int): SKU / entity id\n",
    "        3. \"date\" (datetime): date\n",
    "        4. \"listed\" (int):\n",
    "            - 1: before train period\n",
    "            - 2: train period\n",
    "            - 3: test period\n",
    "            - 4: future\n",
    "        5. any kind of target variable (as set in \"model_def.xlsx\")\n",
    "        6. any kind of produce price variable (as set in \"model_def.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and current model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_p = pd.read_excel('data/data_processed/data_for_sample_p00_w.xlsx', parse_dates=['date'])\n",
    "\n",
    "# sync with FERMATRICA data structure\n",
    "\n",
    "# 'superbrand' as brand name and 'bs_key' as SKU / entity id\n",
    "dt_p['superbrand'] = 'brand_x'\n",
    "dt_p['bs_key'] = 1\n",
    "\n",
    "# 'date'\n",
    "dt_p.rename({'Unnamed: 0': 'date'}, axis=1, inplace=True)\n",
    "\n",
    "# 'Intercept' is not required\n",
    "if 'Intercept' in dt_p.columns:\n",
    "    del dt_p['Intercept']  # much faster than .drop()\n",
    "\n",
    "# some kind of product price is required; set mock\n",
    "dt_p['price'] = 1.0\n",
    "\n",
    "# split dataset into pretrain, train, test, future\n",
    "dt_p['listed'] = 1\n",
    "dt_p.loc[(dt_p['date'] > '2013-06-01') & (dt_p['date'] <= '2017-07-31'), 'listed'] = 2\n",
    "dt_p.loc[(dt_p['date'] > '2017-07-31') & (dt_p['date'] <= '2017-10-30'), 'listed'] = 3\n",
    "dt_p.loc[(dt_p['date'] > '2017-10-30'), 'listed'] = 4\n",
    "#\n",
    "\n",
    "pth = os.path.join(\"code_py\", \"model_data\", \"model_def.xlsx\")\n",
    "\n",
    "model = fm.Model(path=pth\n",
    "                    , adhoc_code=[code_py.adhoc.model]\n",
    "                    , ds=dt_p)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = fm.transform(ds=dt_p\n",
    "                        , model=model\n",
    "                        , set_start=True\n",
    "                        , if_by_ref=True)\n",
    "\n",
    "\n",
    "print(\"time elapsed: \" + str((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if if_opt:\n",
    "    model_back = copy.deepcopy(model)\n",
    "\n",
    "    if cur_algo == 'local':\n",
    "        model = fm.optimize_local_cobyla(dt_p, model\n",
    "                                                , revert_score_sign=True\n",
    "                                                , verbose=True\n",
    "                                                , epochs=1\n",
    "                                                , iters_epoch=500\n",
    "                                                , error_score=1e+12\n",
    "                                                , ftol_abs=.00001)\n",
    "        \n",
    "    elif cur_algo == 'global':\n",
    "        model = fm.optimize_global_ga(dt_p, model\n",
    "                                            , revert_score_sign=False\n",
    "                                            , epochs=1\n",
    "                                            , verbose=True\n",
    "                                            , iters_epoch=10\n",
    "                                            , pop_size=20\n",
    "                                            , pmutation=.1\n",
    "                                            , max_no_improvement=10\n",
    "                                            , error_score=-1e+12\n",
    "                                            , cores=10\n",
    "                                            , save_epoch=os.path.join(os.getcwd(), 'code_py', 'model_data'))\n",
    "\n",
    "    model = copy.deepcopy(model)\n",
    "\n",
    "    winsound.Beep(400, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fm.transform(ds=dt_p\n",
    "                      , model=model\n",
    "                      , set_start=False\n",
    "                      , if_by_ref=True)\n",
    "\n",
    "pred, pred_raw, model = fm.fit_predict(dt_p, model, if_fit=True, return_full=True)\n",
    "pred = fm.fit_predict(dt_p, model, if_fit=False, return_full=False)\n",
    "\n",
    "dt_pred = fm.predict_ext(model, dt_p)\n",
    "\n",
    "\n",
    "rsrc = pkgutil.get_data(\"fermatrica_rep\", \"/res/dict/vis_dict.xlsx\")\n",
    "xlsxio = io.BytesIO(rsrc)\n",
    "vis_dict = pd.read_excel(xlsxio)\n",
    "\n",
    "model_rep = fmr.ModelRep(dt_p, vis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidated statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nScoring\\n')\n",
    "\n",
    "print('Full RMSE : ' + str(round(fm.metrics.rmse(dt_p.loc[dt_p['listed'].isin([2, 3]), model.conf.Y_var], pred[dt_p['listed'].isin([2, 3])]), 2)))\n",
    "print('Full Combined scoring : ' + str(\n",
    "    round(fm.scoring(dt_p.loc[dt_p['listed'].isin([2, 3]), :], pred[dt_p['listed'].isin([2, 3])], model), 5)))\n",
    "\n",
    "print('\\nFit\\n')\n",
    "\n",
    "print('R^2 train: ' + str(round(fm.metrics.r_squared(dt_p.loc[dt_p['listed'].isin([2]), model.conf.Y_var], pred[dt_p['listed'].isin([2])]), 4)))\n",
    "print('MAPE train: ' + str(round(fm.metrics.mapef(dt_p.loc[dt_p['listed'].isin([2]), model.conf.Y_var], pred[dt_p['listed'].isin([2])]), 4)))\n",
    "print('MAPE test: ' + str(round(fm.metrics.mapef(dt_p.loc[dt_p['listed'].isin([3]), model.conf.Y_var], pred[dt_p['listed'].isin([3])]), 4)))\n",
    "\n",
    "print('\\nTests\\n')\n",
    "tests_table = fmr.stats.tests_table_ols(model, dt_pred)\n",
    "\n",
    "print(tests_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nMain model\\n')\n",
    "print(model.obj.models['main'].summary())\n",
    "\n",
    "if 'model_conf_back' in locals() or 'model_conf_back' in globals():\n",
    "\n",
    "    tmp = pd.merge(model.conf.params[['variable', 'fun', 'arg', 'value']]\n",
    "                    , model.conf_back.params[['variable', 'fun', 'arg', 'value']], on=['variable', 'fun', 'arg'])\n",
    "    tmp = tmp[(tmp['value_x'] != tmp['value_y']) & (tmp['value_x'].notna())]\n",
    "\n",
    "    tmp['diff'] = 0\n",
    "    mask = (tmp['value_y'] != 0) & (pd.to_numeric(tmp['value_y'], errors='coerce').notna())\n",
    "    tmp.loc[mask, 'diff'] = tmp.loc[mask, 'value_x'] / tmp.loc[mask, 'value_y'] - 1\n",
    "\n",
    "    print('Changed params\\n')\n",
    "    tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF (Multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_tbl = fmr.stats.vif_table(model.obj.models['main'])\n",
    "vif_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed and predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if if_visual:\n",
    "    \n",
    "    fig = fmr.fit_main_plot_vol(model, dt_pred, model_rep, period='week', show_future=False)\n",
    "    fig.show()\n",
    "\n",
    "    fig = fmr.fit_main_plot_vol(model, dt_pred, model_rep, period='month', show_future=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition and Waterfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_m_m = None\n",
    "\n",
    "if if_visual:\n",
    "\n",
    "    split_m_m = fmr.extract_effect(model, dt_p, model_rep)\n",
    "    split_m_m = split_m_m.sort_values('date')\n",
    "\n",
    "    fig = fmr.decompose_main_plot(split_m_m=split_m_m, brands=None, model_rep=model_rep\n",
    "                                                        , period='m', show_future=False, contour_line=True)\n",
    "    fig.show()\n",
    "\n",
    "    fig = fmr.waterfall_plot(split_m_m=split_m_m, brands=None, model_rep=model_rep\n",
    "                                                    , date_start='2013-01-01', date_end='2017-10-31')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set media prices in \"model_def.xlsx\", sheet \"trans_path_df\", before running\n",
    "\n",
    "curves_data = None\n",
    "\n",
    "if if_curves:\n",
    "    \n",
    "    curves_data = fmr.curves_simple_data(model=model\n",
    "                                        , ds=dt_p\n",
    "                                        , model_rep=model_rep\n",
    "                                        , budget_lim=50  # in millions\n",
    "                                        , budget_step=.01  # in millions\n",
    "                                        , if_precise=False\n",
    "                                        )\n",
    "\n",
    "    fig = fmr.curves_simple_plot(ds=curves_data\n",
    "                                , model_rep=model_rep\n",
    "                                , price=product_price\n",
    "                                , conv=conversion_rate\n",
    "                                )\n",
    "\n",
    "    fig['Incremental Volume'].show()\n",
    "    fig['Incremental Value'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save or export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = ''\n",
    "\n",
    "if if_save:\n",
    "\n",
    "    pth = model.save(dt_p, path=os.path.join(os.getcwd(), 'code_py', 'model_data'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fermat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
